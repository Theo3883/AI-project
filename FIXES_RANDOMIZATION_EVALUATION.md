# Fix-uri: Randomizare È™i Evaluare

## Probleme Identificate È™i Rezolvate

### âŒ Problema 1: Generatori Deterministici
**Simptom**: Fiecare tip de Ã®ntrebare genera mereu exact aceeaÈ™i Ã®ntrebare, fÄƒrÄƒ variaÈ›ie.

**CauzÄƒ**: Generatorii foloseau valori hardcodate pentru toate parametrii:
- Grid world mereu 3x4 cu aceleaÈ™i recompense
- Q-learning mereu cu aceleaÈ™i tranziÈ›ii
- TD-learning mereu cu aceleaÈ™i secvenÈ›e

**SoluÈ›ie âœ…**: 

#### Value Iteration Generator
- **Grid dimensions**: Randomizat Ã®ntre 2-4 rÃ¢nduri Ã— 3-5 coloane
- **Living cost**: Randomizat Ã®ntre -0.04, -0.02, -0.1
- **Goal reward**: Randomizat Ã®ntre 1.0, 2.0, 5.0
- **Penalty reward**: Randomizat Ã®ntre -1.0, -2.0, -5.0
- **Walls**: 0-2 pereÈ›i plasaÈ›i aleator
- **Transition probs**: Intended Ã®ntre 0.7-0.9, perpendicular calculat
- **Discount factor**: 0.8-0.85 (easy), 0.9-0.92 (medium), 0.95-0.99 (hard)
- **Target state**: Aleator din stÄƒrile non-terminale, non-wall

#### Q-Learning Generator
- **NumÄƒr tranziÈ›ii**: 2-3 (easy), 3-5 (medium), 5-8 (hard)
- **StÄƒri**: Generate aleator pe grid 3Ã—4
- **AcÈ›iuni**: Alese aleator din [up, down, left, right]
- **Recompense**: -0.04, -0.02, -0.1, 0.0 (intermediare), 1.0-5.0 (final)
- **Parametri**: Î± âˆˆ {0.1, 0.2, 0.3}, Î³ âˆˆ {0.8, 0.9, 0.95}, Îµ âˆˆ {0.1, 0.2, 0.3}

#### TD-Learning Generator
- **NumÄƒr tranziÈ›ii**: 2-3 (easy), 3-5 (medium/hard)
- **StÄƒri**: Generate aleator similar cu Q-learning
- **Recompense**: -0.04, -0.02 (intermediare), 1.0-2.0 (final)
- **Parametri**: Î± âˆˆ {0.1, 0.2, 0.3}, Î³ âˆˆ {0.8, 0.9, 0.95}

**Rezultat**:
```
Value Iteration - 3 questions:
1. Grid dimensions: 4x4
2. Grid dimensions: 2x3
3. Grid dimensions: 2x4

Q-learning - 3 questions:
1. Parameters: Î±=0.1, Î³=0.9, Îµ=0.2
2. Parameters: Î±=0.3, Î³=0.95, Îµ=0.3
3. Parameters: Î±=0.3, Î³=0.95, Îµ=0.1
```

---

### âŒ Problema 2: Evaluator Prea Permisiv
**Simptom**: RÄƒspunsul parÈ›ial "V((2, 0)) = -0.04" primea 100%, deÈ™i lipsea politica.

**Exemplu**:
```
Correct answer: V((2, 0)) = -0.04, politica: up
User answer: V((2, 0)) = -0.04
Score: 100.0% âŒ INCORECT - ar trebui penalizat
```

**CauzÄƒ**: `MDPEvaluator` compara doar valorile numerice È™i ignora absenÈ›a politicii.

**SoluÈ›ie âœ…**: 

Evaluatorul verificÄƒ acum ce este aÈ™teptat È™i ce este furnizat:

1. **Detectare ce lipseÈ™te**:
   ```python
   correct_has_value = "V(" in question.correct_answer
   correct_has_policy = "politica" in question.correct_answer
   user_has_value = "V(" in user_answer or any(char.isdigit() for char in user_answer)
   user_has_policy = "politica" in user_answer or action_words in user_answer
   ```

2. **Penalizare pentru rÄƒspuns parÈ›ial**:
   - DacÄƒ se aÈ™teaptÄƒ ambele (valoare + politicÄƒ):
     - Doar valoare furnizatÄƒ: `score = value_score * 0.5` (maxim 50%)
     - Doar politicÄƒ furnizatÄƒ: `score = policy_score * 0.5` (maxim 50%)
     - Ambele furnizate: `score = 0.6 * value_score + 0.4 * policy_score`

3. **Feedback explicit**:
   ```
   "Ai furnizat doar valoarea, lipseste politica!"
   "Ai furnizat doar politica, lipseste valoarea!"
   ```

**Rezultat**:
```
Correct answer: V((1, 2)) = -0.10, politica: up
Partial answer: V((1, 0)) = 0.50
Score: 25.0% âœ“ CORECT - penalizat pentru rÄƒspuns parÈ›ial
Feedback: Ai furnizat doar valoarea, lipseste politica!
```

---

## ÃmbunÄƒtÄƒÈ›iri Secundare

### 1. Sortare DeterministicÄƒ Ã®n Output
- Grid-urile afiÈ™eazÄƒ acum stÄƒrile sortate pentru consistenÈ›Äƒ
- UÈ™ureazÄƒ compararea Ã®ntre Ã®ntrebÄƒri diferite

### 2. Validare StÄƒri Ã®n Value Iteration
- Target state ales doar din stÄƒri valide (non-terminal, non-wall)
- EvitÄƒ Ã®ntrebÄƒri imposibile sau nesemnificative

### 3. Parametri Realistici
- Toate valorile randomizate sunt Ã®n range-uri realiste din practicÄƒ
- Î± âˆˆ [0.1, 0.3] - learning rate tipic
- Î³ âˆˆ [0.8, 0.95] - discount factor standard
- Îµ âˆˆ [0.1, 0.3] - exploration rate moderat

---

## Testing

### Test Randomizare
```python
# Generate 3 Value Iteration questions
for i in range(3):
    q = app.generate_questions([QuestionType.VALUE_ITERATION], 1)[0]
    # Each has different dimensions, rewards, walls, etc.
```

**Rezultat**: âœ… Toate 3 Ã®ntrebÄƒrile sunt diferite

### Test Evaluare ParÈ›ialÄƒ
```python
q = app.generate_questions([QuestionType.VALUE_ITERATION], 1)[0]
# Correct: "V((1, 2)) = -0.10, politica: up"

result = app.evaluate_answer(q, "V((1, 0)) = 0.50")  # Partial answer
# Score: 25.0% (penalizat pentru lipsa politicii)
```

**Rezultat**: âœ… RÄƒspuns parÈ›ial penalizat corect

### Test Suite
```bash
python3 tests/test_mdp_rl.py
```

**Rezultat**: âœ… All 11 tests passed

---

## Impact

### Ãnainte:
- âŒ AcelaÈ™i grid 3Ã—4 mereu
- âŒ AceleaÈ™i tranziÈ›ii Q-learning
- âŒ 100% pentru rÄƒspuns parÈ›ial
- âŒ LipsÄƒ varietate Ã®n antrenament

### DupÄƒ:
- âœ… Grid-uri diferite (2-4 Ã— 3-5)
- âœ… TranziÈ›ii randomizate
- âœ… Evaluare corectÄƒ (50% max pentru parÈ›ial)
- âœ… Varietate infinitÄƒ de Ã®ntrebÄƒri
- âœ… Feedback explicit pentru rÄƒspunsuri incomplete

---

## Exemplu Complet

### Generare 3 ÃntrebÄƒri Value Iteration:

**Ãntrebare 1**:
```
Grid World MDP de dimensiune 4x4
Î³ = 0.9
(0,3): 2.0 (TERMINAL) - goal
(2,1): -1.0 (TERMINAL) - penalty
(1,1): PERETE
Living cost: -0.04
Target: (3,2)
```

**Ãntrebare 2**:
```
Grid World MDP de dimensiune 2x3
Î³ = 0.92
(0,2): 5.0 (TERMINAL) - goal
(1,1): -2.0 (TERMINAL) - penalty
Living cost: -0.02
Target: (0,1)
```

**Ãntrebare 3**:
```
Grid World MDP de dimensiune 3x5
Î³ = 0.85
(2,4): 1.0 (TERMINAL) - goal
Living cost: -0.1
No walls
Target: (1,2)
```

### Evaluare RÄƒspunsuri:

| RÄƒspuns | Score | Feedback |
|---------|-------|----------|
| `V((1,2)) = -0.10, politica: up` | 100% | Complet corect âœ“ |
| `V((1,2)) = -0.10` | 50% | LipseÈ™te politica! |
| `politica: up` | 50% | LipseÈ™te valoarea! |
| `V((1,2)) = -0.15, politica: up` | 60% | Valoare greÈ™itÄƒ, politicÄƒ OK |
| `(rÄƒspuns gol)` | 0% | RÄƒspuns incomplet |

---

## FiÈ™iere Modificate

1. **`smartest/core/generators.py`**
   - `ValueIterationGenerator._create_grid_world()` - randomizare completÄƒ
   - `ValueIterationGenerator.generate()` - target state aleator
   - `QLearningGenerator._generate_transitions()` - tranziÈ›ii random
   - `QLearningGenerator.generate()` - parametri random
   - `TDLearningGenerator.generate()` - tranziÈ›ii È™i parametri random

2. **`smartest/core/evaluators.py`**
   - `MDPEvaluator.evaluate()` - logicÄƒ completÄƒ de penalizare pentru rÄƒspunsuri parÈ›iale

---

## Concluzii

âœ… **Problema 1 rezolvatÄƒ**: Generatorii creeazÄƒ acum Ã®ntrebÄƒri variate  
âœ… **Problema 2 rezolvatÄƒ**: Evaluatorul penalizeazÄƒ corect rÄƒspunsurile parÈ›iale  
âœ… **Toate testele trec**: 11/11 tests passed  
âœ… **0 erori de linting**  
âœ… **Varietate infinitÄƒ**: StudenÈ›ii nu mai pot memoriza Ã®ntrebÄƒrile

**Ready for production!** ğŸš€

